# app/config.py
"""
åº”ç”¨ç¨‹åºé…ç½®æ¨¡å—
è´Ÿè´£åŠ è½½ç¯å¢ƒå˜é‡ã€å®šä¹‰åŸºç¡€è·¯å¾„å’Œé»˜è®¤é…ç½®
"""
import os
import socket
from pathlib import Path
from typing import Optional

from dotenv import load_dotenv


def setup_network() -> None:
    """
    æ™ºèƒ½ç½‘ç»œé…ç½®ï¼šæ£€æµ‹ä»£ç†å¯ç”¨æ€§
    - å¦‚æœä»£ç†å¯ç”¨ï¼ˆç«¯å£7890ï¼‰ï¼Œè®¾ç½®ä»£ç†ç›´æ¥è®¿é—® Hugging Face
    - å¦‚æœä»£ç†ä¸å¯ç”¨ï¼Œä½¿ç”¨å›½å†…é•œåƒ
    """
    proxy_host: str = "127.0.0.1"
    proxy_port: int = 7890

    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex((proxy_host, proxy_port))
        sock.close()

        if result == 0:
            proxy_url = f"http://{proxy_host}:{proxy_port}"
            os.environ["HTTP_PROXY"] = proxy_url
            os.environ["HTTPS_PROXY"] = proxy_url
            print(f"ğŸŒ æ£€æµ‹åˆ°ä»£ç† ({proxy_url})ï¼Œä½¿ç”¨ä»£ç†è®¿é—® Hugging Face")
        else:
            raise ConnectionError("Proxy not available")
    except Exception:
        os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
        print("ğŸª æœªæ£€æµ‹åˆ°ä»£ç†ï¼Œä½¿ç”¨ Hugging Face é•œåƒ (hf-mirror.com)")


# åœ¨åŠ è½½å…¶ä»–æ¨¡å—å‰æ‰§è¡Œç½‘ç»œé…ç½®
setup_network()

load_dotenv()

# =============================================================================
# åŸºç¡€è·¯å¾„é…ç½®
# =============================================================================
BASE_DIR: Path = Path(".")
HISTORY_DIR: Path = BASE_DIR / "history"
UPLOAD_DIR: Path = BASE_DIR / "data_uploads"
KB_META_FILE: Path = BASE_DIR / "kb_metadata.json"
CHROMA_PATH: str = "chroma_db"

# ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
HISTORY_DIR.mkdir(parents=True, exist_ok=True)
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# =============================================================================
# é»˜è®¤ API é…ç½®
# =============================================================================
DEFAULT_API_URL: str = os.getenv("PROXY_BASE_URL", "https://api.openai.com/v1")
DEFAULT_API_KEY: str = os.getenv("PROXY_API_KEY", "")
DEFAULT_MODEL: str = os.getenv("TARGET_MODEL", "gpt-3.5-turbo")