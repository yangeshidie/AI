import os
import sys
from openai import OpenAI
from dotenv import load_dotenv


class ChatApp:
    def __init__(self):
        # 1. åˆå§‹åŒ–é…ç½®
        load_dotenv()
        self.base_url = os.getenv("PROXY_BASE_URL")
        self.api_key = os.getenv("PROXY_API_KEY")

        # é»˜è®¤æ¨¡å‹ (å…œåº•ç”¨)
        self.current_model = os.getenv("TARGET_MODEL", "gemini-1.5-flash")

        # ç¼“å­˜æ¨¡å‹åˆ—è¡¨
        self.available_models = []

        # å†å²è®°å½•
        self.history = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜é£è¶£çš„AIåŠ©æ‰‹ã€‚"}
        ]

        # 2. å»ºç«‹å®¢æˆ·ç«¯
        if not self.base_url or not self.api_key:
            print("âŒ é”™è¯¯ï¼šè¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
            sys.exit(1)

        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key)

        # 3. å¯åŠ¨æ—¶è‡ªåŠ¨æ‹‰å–æ¨¡å‹
        print("æ­£åœ¨åˆå§‹åŒ–ï¼Œè·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
        self._fetch_remote_models()

    def _fetch_remote_models(self):
        """å†…éƒ¨æ–¹æ³•ï¼šä»æœåŠ¡å™¨è·å–æ¨¡å‹åˆ—è¡¨å¹¶ç¼“å­˜"""
        try:
            model_list = self.client.models.list()
            # æå–IDå¹¶æ’åº
            self.available_models = sorted([m.id for m in model_list.data])
            print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼ç¼“å­˜äº† {len(self.available_models)} ä¸ªæ¨¡å‹ã€‚")
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ ({e})")
            print("å°†ä»…ä½¿ç”¨ .env ä¸­é…ç½®çš„é»˜è®¤æ¨¡å‹ã€‚")
            self.available_models = []

    def select_model_ui(self):
        """äº¤äº’å¼é€‰æ‹©æ¨¡å‹ç•Œé¢"""
        if not self.available_models:
            print("âŒ æ²¡æœ‰ç¼“å­˜çš„æ¨¡å‹åˆ—è¡¨ï¼Œæ— æ³•åˆ‡æ¢ (å¯èƒ½ç”±äºåˆå§‹åŒ–å¤±è´¥)ã€‚")
            # å…è®¸æ‰‹åŠ¨è¾“å…¥ä½œä¸ºå¤‡é€‰
            manual = input("æ˜¯å¦æ‰‹åŠ¨è¾“å…¥æ¨¡å‹å? (y/n): ")
            if manual.lower() == 'y':
                new_name = input("è¯·è¾“å…¥æ¨¡å‹ID: ")
                if new_name:
                    self.current_model = new_name
                    print(f"âœ… å·²åˆ‡æ¢åˆ°: {self.current_model}")
            return

        print("\n--- å¯ç”¨æ¨¡å‹åˆ—è¡¨ ---")
        for idx, model_id in enumerate(self.available_models):
            # æ ‡è®°å½“å‰æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹
            marker = "*" if model_id == self.current_model else " "
            print(f"[{idx + 1}]{marker} {model_id}")
        print("--------------------")

        choice = input(f"è¯·è¾“å…¥åºå·åˆ‡æ¢æ¨¡å‹ (å½“å‰: {self.current_model}, å›è½¦å–æ¶ˆ): ")

        if not choice.strip():
            return

        try:
            idx = int(choice) - 1
            if 0 <= idx < len(self.available_models):
                self.current_model = self.available_models[idx]
                print(f"âœ… åˆ‡æ¢æˆåŠŸï¼å½“å‰æ¨¡å‹: {self.current_model}")
            else:
                print("âŒ åºå·æ— æ•ˆã€‚")
        except ValueError:
            print("âŒ è¾“å…¥é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—ã€‚")

    def run(self):
        """ä¸»å¾ªç¯"""
        print("\n" + "=" * 50)
        print(f"æ¬¢è¿ä½¿ç”¨ Python Chat CLI")
        print(f"å½“å‰æ¨¡å‹: {self.current_model}")
        print("æŒ‡ä»¤æç¤º:")
        print("  /model  - åˆ‡æ¢æ¨¡å‹")
        print("  /clear  - æ¸…ç©ºå¯¹è¯å†å²")
        print("  /quit   - é€€å‡ºç¨‹åº")
        print("=" * 50 + "\n")

        while True:
            try:
                user_input = input("\nä½ : ").strip()

                # å¤„ç†ç©ºè¾“å…¥
                if not user_input:
                    continue

                # --- æŒ‡ä»¤å¤„ç†åŒºåŸŸ ---
                if user_input.lower() in ["/quit", "exit", "quit"]:
                    print("å†è§ï¼")
                    break

                if user_input.lower() == "/model":
                    self.select_model_ui()
                    continue  # è·³è¿‡æœ¬æ¬¡å¯¹è¯å‘é€

                if user_input.lower() == "/clear":
                    self.history = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜é£è¶£çš„AIåŠ©æ‰‹ã€‚"}]
                    print("ğŸ§¹ è®°å¿†å·²æ¸…é™¤ã€‚")
                    continue
                # ------------------

                # æ­£å¸¸å¯¹è¯é€»è¾‘
                self.history.append({"role": "user", "content": user_input})

                print(f"AI ({self.current_model}): ", end="", flush=True)

                response = self.client.chat.completions.create(
                    model=self.current_model,  # ä½¿ç”¨åŠ¨æ€å˜é‡
                    messages=self.history,
                    stream=True,
                    temperature=0.7,
                )

                full_reply = ""
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        print(content, end="", flush=True)
                        full_reply += content

                self.history.append({"role": "assistant", "content": full_reply})
                print("")  # æ¢è¡Œ

            except KeyboardInterrupt:
                print("\nç¨‹åºå·²åœæ­¢ã€‚")
                break
            except Exception as e:
                print(f"\nâŒ è¯·æ±‚é”™è¯¯: {e}")


if __name__ == "__main__":
    app = ChatApp()
    app.run()